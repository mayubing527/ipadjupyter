{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第14章 pandas编程基础\n",
    "* **Python基本库**：序列数据的基本类型，如列表、元组、字典、集合等。\n",
    "* **numpy工具库**：向量、数组、矩阵等数据类型。\n",
    "    * array\n",
    "* **pandas工具库**：具有行索引、列索引或多个行列索引的数据类型。\n",
    "    * Series\n",
    "    * DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1 关于pandas\n",
    "* 在Python中，pandas是基于NumPy数组构建的，使数据预处理、清洗、分析工作变得更快更简单。\n",
    "    * pandas是专门为处理表格和混杂数据设计的（异质数据，结构数组的延伸）；\n",
    "    * 而numpy更适合处理统一的数值数组数据（同质数据）。\n",
    "* 使用下面格式引入pandas包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2 pandas的数据结构\n",
    "* Pandas提供了最重要的两种数据结构类型：Series（一维数据）与 DataFrame（二维数据）。\n",
    "    * 这两种数据结构足以处理金融、统计、社会科学、工程等领域里的大多数典型实例。\n",
    "\n",
    "|维数|名称|描述|\n",
    "|--|--|--|\n",
    "|1|Series|带标签的一维同构数组|\n",
    "|2|DataFrame|带标签的，大小可变的，二维异构表格|\n",
    "\n",
    "* 两种数据结构可以使用如下语句调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series,DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.1 Series\n",
    "* 类Series的实例是一种类似于一维数组的对象，其基本内容包含**数据**和**数据标签**（即**索引**）。\n",
    "    * 即：index和values两部分，可以通过索引的方式选取Series中的单个或一组值。\n",
    "\n",
    "#### （1）Series的创建：pd.Series(data, index=[ ])\n",
    "* 第一个参数data：可以是列表、字典（字典的键将作为Series的索引）、数组或DataFrame中的某一行或某一列。\n",
    "* 第二个参数index：是Series中数据的索引，可以省略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=pd.Series([101,78,59,63])\n",
    "print(s1)   #由于我们没有为数据指定索引，于是会自动创建一个0到N-1（N为数据的长度）的整数型索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Series的索引在左边，值在右边。\n",
    "    * 默认索引为0,1,2,…\n",
    "* **values**和**index**属性可以得到Series的数据和索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s1.values)\n",
    "print(s1.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Series的索引**可以通过赋值的方式直接更改，也可以在创建Series时直接通过指定index的方式进行自定义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.index=['No.1','No.2','No.3','No.4']\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=pd.Series([101,78,59,63], index=['No.1','No.2','No.3','No.4'])\n",
    "s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **pandas的缺失数据被标记为NaN**。\n",
    "* 检测缺失值的方法：\n",
    "    * 用pandas中的isnull、notnull函数\n",
    "    * 用Series实例对象的isnull、notnull方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series({\"Name\":'ZhangSan', \"Gender\":'Male', \"Age\":19})  #字典的键将作为Series的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3=pd.Series({\"Name\":'ZhangSan', \"Gender\":'Male', \"Age\":19}, index=[\"Name\",\"Gender\",\"Height\",\"Age\",\"Weight\"])\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4=pd.Series([101,78,59,63], index=['No.1','No.2','No.3','No.4','No.5'])  #报错！\n",
    "s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2]\n",
    "a[2]=1  #报错！\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b={\"Name\":'ZhangSan', \"Gender\":'Male', \"Age\":19}\n",
    "b[\"Weight\"]=66\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）Series类型的操作\n",
    "* Series可以通过索引访问到其具体的数据元素："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2['No.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2[['No.1','No.3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Series类型索引、切片、矢量化运算的操作类似于ndarray，同样的类似Python字典类型的操作，包括保留字in操作、使用.get()方法。\n",
    "* Series和ndarray之间的主要区别在于**Series之间的操作会根据索引自动对齐数据**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.arange(10)\n",
    "print(a*2)\n",
    "sa=pd.Series(a)\n",
    "print(sa*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）reindex方法：可以使得Series按照指定的index索引顺序实现重新排序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3=pd.Series({\"Name\":'ZhangSan', \"Gender\":'Male', \"Age\":19}, index=[\"Name\",\"Gender\",\"Height\",\"Age\",\"Weight\"])\n",
    "print(s3)\n",
    "id=[\"Name\",\"Gender\",\"Height\",\"Age\",\"Weight\"]\n",
    "id.sort()\n",
    "print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.reindex(index=id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* reindex方法并不会改变原Series的索引，只是返回一个经过重新索引的视图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.2 DataFrame\n",
    "* DataFrame是一个类似**电子表格**型的数据类型，**每列值类型可以不同**，是最常用的pandas对象。\n",
    "* DataFrame既有行索引也有列索引，它可以被看做由Series组成的字典（共用同一个索引）。\n",
    "* DataFrame中的数据是以一个或多个二维块存放的（而不是列表、字典或别的一维数据结构）。\n",
    "\n",
    "#### 14.2.2.1 创建DataFrame实例对象\n",
    "* pd.DataFrame(data,columns = [ ],index = [ ])：columns和index为指定的列、行索引，并按照顺序排列。\n",
    "* 创建DataFrame最常用方式是直接用**字典**或**numpy数组**来生成。\n",
    "\n",
    "#### （1）使用字典构造DataFrame\n",
    "* 利用DataFrame()函数来创建DataFrame最常用的是直接传入一个由**等长列表或数组构成的字典**：\n",
    "    * 字典的键直接被设置为**列索引**；\n",
    "    * 字典的值（列表或数组）为相应列索引下的所有元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Name': ['ZhangSan', 'LiSi', 'WangWu', 'ZhaoLiu', 'QianQi','SunBa'],\n",
    "      'Subject': ['Literature','History','English','Maths','Physics','Chemics'],\n",
    "      'Score': [98, 76, 84, 70, 93, 83]}\n",
    "df=pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如果创建时指定了columns和index索引，则按照索引顺序排列。\n",
    "    * 并且如果传入的列在数据中找不到，就会在结果中产生缺失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(data, columns=['Name', 'Subject', 'Score', 'Number'],\n",
    "                    index=['one', 'two', 'three', 'four', 'five', 'six'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 另一种常见的创建DataFrame方式是使用**嵌套字典**：\n",
    "    * **外层**字典的键作为**列索引**；\n",
    "    * **内层**字典的键作为**行索引**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop={'Nevada': {2001: 2.4, 2002: 2.9},\n",
    "     'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}\n",
    "df3=pd.DataFrame(pop)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）使用numpy数组构造DataFrame\n",
    "* 可以根据**二维数组**直接构造DataFrame："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n=np.random.randn(10,5)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf=pd.DataFrame(n)\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(n.reshape(2,5,5))  #ValueError: Must pass 2-d input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）直接读入csv文件或excel文件构造DataFrame\n",
    "* **pandas.read_csv()**：读取csv文件；\n",
    "* **pandas.read_excel()**：读取excel文件\n",
    "    * io：文件名，字符串类型\n",
    "    * encoding：设置编码方式，utf8或gbk\n",
    "    * index_col：设置为行索引的列名，字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.read_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"chap14_data.xlsx\")  #读入数据\n",
    "print('数据的维度是：', data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （4）其他数据源构造DataFrame\n",
    "\n",
    "#### 表14-1：pandas可读入/写入的主要数据类型\n",
    "\n",
    "|描述|读入|导出|\n",
    "|--|--|--|\n",
    "|以逗号作为分隔符的数据|read_csv|to_csv|\n",
    "|MS Excel文件|read_excel|to_excel|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.2.2.2 数据导出\n",
    "* 参考表14-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"chap_14_newdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"chap_14_newdata.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.2.2.3 DataFrame的索引和切片\n",
    "* DataFrame可以按行或列进行索引或切片，即：提取数据的子集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Name': ['ZhangSan', 'LiSi', 'WangWu', 'ZhaoLiu', 'QianQi','SunBa'],\n",
    "      'Subject': ['Literature','History','English','Maths','Physics','Chemics'],\n",
    "      'Score': [98, 76, 84, 70, 93, 83]}\n",
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 直接通过**列索引**取整列元素："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Subject']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 通过**行索引**获得整行元素：\n",
    "    * loc：用索引标签进行索引\n",
    "    * iloc：用索引号进行索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[0,2],[\"Name\",\"Score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[0,2],[0,2]]  #报错！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[0,2],[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[0,2],[\"Name\",\"Score\"]]  #报错！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DataFrame也可进行**逻辑索引/切片**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Score>80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,[0,2]][df.Score>80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.2.2.4 行列操作\n",
    "\n",
    "#### （1）改变列的顺序：columns参数\n",
    "* 方法1：通过对DataFrame函数中的columns参数进行列指定顺序\n",
    "* 方法2：通过对reindex方法中的columns参数进行列指定顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Name': ['ZhangSan', 'LiSi', 'WangWu', 'ZhaoLiu', 'QianQi','SunBa'],\n",
    "      'Subject': ['Literature','History','English','Maths','Physics','Chemics'],\n",
    "      'Score': [98, 76, 84, 70, 93, 83]}\n",
    "df=pd.DataFrame(data, columns=[\"Name\",\"Score\",\"Subject\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reindex(columns=[\"Name\",\"Subject\",\"Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 在实际数据分析中，改变行列顺序并不会影响分析结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）修改或增加行/列的数据：直接赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0,'Score']=100  #修改元素\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Homework\"]=90  #增加列\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）删除行/列的数据：del语句或drop方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"Homework\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Subject\", axis=1)  #axis=1表示删除列，axis=0表示删除行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Subject\", axis=1, inplace=True)  #inplace=True表示原数据被替换，默认为False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3 pandas的数据操作\n",
    "\n",
    "### 14.3.1 排序：sort_index和sort_values\n",
    "* **注意：在排序时，任何缺失值默认都会被放到末尾。**\n",
    "\n",
    "#### （1）sort_index方法\n",
    "* sort_index()方法：根据指定轴（行或列）索引的值进行排序。\n",
    "\n",
    "|参数|描述||备注|\n",
    "|--|--|--|--|\n",
    "|axis=0|根据0轴的索引值排序|默认值|对于Series只能是axis=0|\n",
    "|axis=1|根据1轴的索引值排序|||\n",
    "|ascending=True|升序排序|默认值||\n",
    "|ascending=False|降序排序|||\n",
    "\n",
    "#### Series的sort_index方法示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssort=pd.Series(range(5), index=['b','a','d','e','c'])\n",
    "print(ssort)\n",
    "ssort.sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame的sort_index方法示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index=[102,101,106,104,103,105]\n",
    "print(df)\n",
    "print(\"\\n\",df.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis=1)  #列的升序排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis=1,ascending=False)  #列的降序排列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）sort_values方法\n",
    "* **sort_values方法：在指定轴上根据数值进行排序，默认升序**。\n",
    "\n",
    "|参数|描述||备注|\n",
    "|--|--|--|--|\n",
    "|axis=0|根据0轴的索引值排序|默认值|对于Series只能是axis=0|\n",
    "|axis=1|根据1轴的索引值排序|||\n",
    "|ascending=True|升序排序|默认值||\n",
    "|ascending=False|降序排序|||\n",
    "|by|按照DataFrame的某个/些列进行排序||仅适用于DataFrame|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[105,'Score']=84\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Score','Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.2 排名：rank方法\n",
    "* **排名（秩）**：指从1开始一直到数据中有效数据的数量为止，返回数据在排序中的位置。\n",
    "* **rank()方法中的method参数**：处理多个数据值相同其排名计算的问题。\n",
    "\n",
    "|method参数取值|描述|备注|\n",
    "|--|--|--|\n",
    "|method='average'|在相同排名中，为各个值的平均分配排名|默认值|\n",
    "|method='min'|使用整个相同排名的最小排名||\n",
    "|method='max'|使用整个相同排名的最大排名||\n",
    "|method='first'|按值在原始数据中出现的顺序分配排名||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrank=pd.Series([10,12,9,9,14,4,2,4,9,1])\n",
    "rrank.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrank.rank(method='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrank.rank(method='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.3 运算\n",
    "* pandas最重要的一个功能就是**对不同索引的对象进行算数运算**（矢量化运算），而且在运算时系统会按照各自索引进行**自动对齐**。\n",
    "    * 若参加运算的数据中存在不同索引，则结果的索引就是所有索引的**并集**，对应的值标记为**NaN**（即pandas中的默认**缺失值**）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs1=pd.Series(range(1,6),index=['a','b','c','d','e'])\n",
    "cs2=pd.Series(range(10,80,10),index=['a','b','c','d','e','f','g'])\n",
    "print(cs1)\n",
    "print(cs2)\n",
    "cs1+cs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf1=pd.DataFrame(np.arange(10).reshape((2,5)),columns=list('abcde'))\n",
    "cdf2=pd.DataFrame(np.arange(12).reshape((3,4)),columns=list('abcd'))\n",
    "print(cdf1)\n",
    "print(cdf2)\n",
    "cdf1+cdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 可以使用add（加）、sub（减）、div（除）和mul（乘）等方法，将其他DataFrame对象的值传入指定的DataFrame对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf1.add(cdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf1.add(cdf2, fill_value=0)  #参数fill_value表示缺失值填充内容，但当两者均为缺失值时会直接返回NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回顾：numpy中的ufunc运算\n",
    "* ufunc（universal function）：numpy通用函数，是一种能对数组中每个元素进行操作的函数。\n",
    "* 具体内置函数及运算符号的列表参考：https://blog.csdn.net/unixtch/article/details/78531585\n",
    "\n",
    "### 14.3.4 函数应用与映射\n",
    "\n",
    "#### （1）ufunc运算\n",
    "* numpy的**ufunc**也可以应用于pandas对象，即：可将函数应用到Series或DataFrame中的每一个元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversef=lambda x:-x\n",
    "print(cs1)\n",
    "reversef(cs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cdf1)\n",
    "reversef(cdf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）apply方法\n",
    "* DataFrame对象的**apply方法**可以将函数应用到各行或各列上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cs1)\n",
    "cs1.apply(reversef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cdf1)\n",
    "cdf1.apply(reversef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）applymap方法\n",
    "* apply、applymap和map方法均可对对象中的数据传递函数进行操作，区别如下：\n",
    "\n",
    "|方法|级别|作用对象|\n",
    "|--|--|--|\n",
    "|apply||DataFrame的一列或一行数据|\n",
    "|applymap|元素级|每个DataFrame的每个数据|\n",
    "|map|元素级|对Series中的每个数据调用一次函数|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf1.applymap(reversef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 若传递给apply方法的函数返回值是由多个值组成的Series，可以使用**applymap方法**格式化各个元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(x):\n",
    "    return pd.Series([x.min(),x.max(),x.max()-x.min(),x.mean(),x.count()],\n",
    "                     index=['Min','Max','Range','Mean','N'])\n",
    "outformat=lambda x: \"%.2f\" %x\n",
    "print(cdf1)\n",
    "cdf1.apply(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf1.apply(statistics).applymap(outformat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.5 分组：groupby方法\n",
    "* pandas可以使用**groupby方法**对数据进行分组分析，主要有如下两种方式：\n",
    "    * 1. 根据表本身的某一列或多列内容进行分组聚合\n",
    "    * 2. 通过字典或者Series进行分组\n",
    "    \n",
    "#### 1. 根据表本身的某一列或多列内容进行分组聚合\n",
    "* 这个是groupby的最常见操作，根据某一列的内容分为不同的维度进行拆解，将同一维度的再进行聚合\n",
    "\n",
    "#### （1）按一列进行聚合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data={'Name': ['ZhangSan', 'LiSi', 'WangWu', 'ZhaoLiu', 'QianQi','SunBa'],\n",
    "      'Gender':['Male','Female','Female','Male','Male','Female'],\n",
    "      'Grade':['2019','2019','2018','2019','2018','2018'],\n",
    "      'Subject': ['Literature','History','English','Maths','Physics','Chemics'],\n",
    "      'Score': [98, 76, 84, 70, 93, 83]}\n",
    "df=pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.groupby('Gender'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[i for i in df.groupby('Gender')]  #返回值为列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Gender').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）按多列进行聚合，则看的是多列之间维度的笛卡尔积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Gender','Grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.groupby(['Gender','Grade']):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 通过字典或者Series进行分组\n",
    "\n",
    "#### 问题情境：一共有5个同学分别对5样东西做了一个评价，0-5表示对该物品的喜爱程度，随着数值的升高，程度也在不断加深。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "people=pd.DataFrame(np.random.randint(low=0,high=6,size=(5,5)),\n",
    "                    columns=['香蕉','苹果','橘子','眼影','眼线'],\n",
    "                    index=['Joe','Steve','Wes','Jim','Travis'])\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 但是可以明显发现这五样物品可以分为两类：“水果”和“化妆品”。\n",
    "\n",
    "#### 问题：我想知道这五名同学对水果和化妆品的平均喜爱程度是什么样的？\n",
    "* **solution1：通过字典分组**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping={'香蕉':'水果','苹果':'水果','橘子':'水果','眼影':'化妆品','眼线':'化妆品'}\n",
    "people.groupby(mapping,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in people.groupby(mapping,axis=1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **solution2：通过Series分组**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping2=pd.Series(mapping)\n",
    "mapping2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.groupby(mapping2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in people.groupby(mapping2,axis=1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**总结**：\n",
    "* 无论solution1还是2，本质上，都是找index（Series）或者key（字典）与数据表本身的行或者列之间的对应关系。\n",
    "* 在groupby之后所使用的聚合函数都是对每个group的操作，聚合函数操作完之后，再将其合并到一个DataFrame中，每一个group最后都变成了一列（或者一行）。\n",
    "\n",
    "#### 3. 分组数据分析\n",
    "* 经过分组处理的数据便可以进行分组数据分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(people)\n",
    "people.groupby(mapping,axis=1).mean()  #分组均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(people)\n",
    "people.groupby(mapping,axis=1).describe()  #分组描述统计分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.6 合并\n",
    "* pandas提供了很多函数或方法对pandas的数据对象进行合并：\n",
    "    * 函数：concat、merge\n",
    "    * 方法：append、join\n",
    "* 这里主要讲述常用的三种：（参考：https://mp.weixin.qq.com/s/686SKGkIrlaYdtGfX0uKEQ ）\n",
    "    * 1. **merge函数**：主要基于两个dataframe的共同列进行合并\n",
    "    * 2. **join方法**：主要基于两个dataframe的索引进行合并\n",
    "    * 3. **concat函数**：是对series或dataframe进行行拼接或列拼接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.3.6.1 merge函数\n",
    "* pandas的merge方法是基于共同列，将两个dataframe连接起来。\n",
    "* merge方法的主要参数：\n",
    "    * left/right：左/右位置的dataframe。\n",
    "    * how：数据合并的方式。\n",
    "        * left：左连接，基于左dataframe列的数据合并；\n",
    "        * right：右连接，基于右dataframe列的数据合并；\n",
    "        * outer：外连接，基于列的数据外合并（取并集）；\n",
    "        * inner：内连接，基于列的数据内合并（取交集）；默认为'inner'。\n",
    "    * on：用来合并的列名，这个参数需要保证两个dataframe有相同的列名。\n",
    "    * left_on/right_on：左/右dataframe合并的列名，也可为索引，数组和列表。\n",
    "    * left_index/right_index：是否以index作为数据合并的列名，True表示是。\n",
    "    * sort：根据dataframe合并的keys排序，默认是。\n",
    "    * suffixes：若有相同列且该列没有作为合并的列，可通过suffixes设置该列的后缀名，一般为元组和列表类型。\n",
    "* merges通过设置how参数选择两个dataframe的连接方式，有内连接，外连接，左连接，右连接，下面通过例子介绍连接的含义。\n",
    "\n",
    "#### （1）内连接\n",
    "* how='inner'，dataframe的链接方式为内连接，我们可以理解基于共同列的交集进行连接，参数on设置连接的共有列名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单列的内连接\n",
    "# 定义df1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1=pd.DataFrame({'alpha':['A','B','B','C','D','E'],'feature1':[1,1,2,3,3,1],\n",
    "            'feature2':['low','medium','medium','high','low','high']})\n",
    "# 定义df2\n",
    "df2 = pd.DataFrame({'alpha':['A','A','B','F'],'pazham':['apple','orange','pine','pear'],\n",
    "            'kilo':['high','low','high','medium'],'price':np.array([5,6,5,7])})\n",
    "print(df1)\n",
    "print(df2)\n",
    "# 基于共同列alpha的内连接\n",
    "pd.merge(df1,df2,how='inner',on='alpha')  #取共同列alpha值的交集进行连接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）外连接\n",
    "* how='outer'，dataframe的链接方式为外连接，我们可以理解基于共同列的并集进行连接，参数on设置连接的共有列名。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单列的外连接\n",
    "# 定义df1\n",
    "df1 = pd.DataFrame({'alpha':['A','B','B','C','D','E'],'feature1':[1,1,2,3,3,1],\n",
    "                'feature2':['low','medium','medium','high','low','high']})\n",
    "# 定义df2\n",
    "df2 = pd.DataFrame({'alpha':['A','A','B','F'],'pazham':['apple','orange','pine','pear'],\n",
    "                        'kilo':['high','low','high','medium'],'price':np.array([5,6,5,7])})\n",
    "# 基于共同列alpha的内连接\n",
    "pd.merge(df1,df2,how='outer',on='alpha')  #若两个dataframe间除了on设置的连接列外并无相同列，则该列的值置为NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）左连接\n",
    "* how='left'，dataframe的链接方式为左连接，我们可以理解基于左边位置dataframe的列进行连接，参数on设置连接的共有列名。　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单列的左连接\n",
    "# 定义df1\n",
    "df1 = pd.DataFrame({'alpha':['A','B','B','C','D','E'],'feature1':[1,1,2,3,3,1],\n",
    "    'feature2':['low','medium','medium','high','low','high']})\n",
    "# 定义df2\n",
    "df2 = pd.DataFrame({'alpha':['A','A','B','F'],'pazham':['apple','orange','pine','pear'],\n",
    "                        'kilo':['high','low','high','medium'],'price':np.array([5,6,5,7])})\n",
    "# 基于共同列alpha的左连接\n",
    "pd.merge(df1,df2,how='left',on='alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为df2的连接列alpha有两个'A'值，所以左连接的df5有两个'A'值，若两个dataframe间除了on设置的连接列外并无相同列，则该列的值置为NaN。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （4）右连接\n",
    "* how='right'，dataframe的链接方式为左连接，我们可以理解基于右边位置dataframe的列进行连接，参数on设置连接的共有列名。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单列的右连接\n",
    "# 定义df1\n",
    "df1 = pd.DataFrame({'alpha':['A','B','B','C','D','E'],'feature1':[1,1,2,3,3,1],\n",
    "'feature2':['low','medium','medium','high','low','high']})\n",
    "# 定义df2\n",
    "df2 = pd.DataFrame({'alpha':['A','A','B','F'],'pazham':['apple','orange','pine','pear'],\n",
    "                        'kilo':['high','low','high','medium'],'price':np.array([5,6,5,7])})\n",
    "# 基于共同列alpha的右连接\n",
    "pd.merge(df1,df2,how='right',on='alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为df1的连接列alpha有两个'B'值，所以右连接的df6有两个'B'值。若两个dataframe间除了on设置的连接列外并无相同列，则该列的值置为NaN。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （5）基于多列的连接算法 \n",
    "* 多列连接的算法与单列连接一致，本节只介绍基于多列的内连接和右连接，大家可自己编码并按照本文给出的图解方式去理解外连接和左连接。 \n",
    "\n",
    "#### 多列的内连接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多列的内连接\n",
    "# 定义df1\n",
    "df1 = pd.DataFrame({'alpha':['A','B','B','C','D','E'],'beta':['a','a','b','c','c','e'],\n",
    "                    'feature1':[1,1,2,3,3,1],'feature2':['low','medium','medium','high','low','high']})\n",
    "# 定义df2\n",
    "df2 = pd.DataFrame({'alpha':['A','A','B','F'],'beta':['d','d','b','f'],'pazham':['apple','orange','pine','pear'],\n",
    "                        'kilo':['high','low','high','medium'],'price':np.array([5,6,5,7])})\n",
    "# 基于共同列alpha和beta的内连接\n",
    "pd.merge(df1,df2,on=['alpha','beta'],how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多列的右连接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多列的右连接\n",
    "# 定义df1\n",
    "df1 = pd.DataFrame({'alpha':['A','B','B','C','D','E'],'beta':['a','a','b','c','c','e'],\n",
    "                    'feature1':[1,1,2,3,3,1],'feature2':['low','medium','medium','high','low','high']})\n",
    "# 定义df2\n",
    "df2 = pd.DataFrame({'alpha':['A','A','B','F'],'beta':['d','d','b','f'],'pazham':['apple','orange','pine','pear'],\n",
    "                        'kilo':['high','low','high','medium'],'price':np.array([5,6,5,7])})\n",
    "print(df1)\n",
    "print(df2)\n",
    "\n",
    "# 基于共同列alpha和beta的右连接\n",
    "pd.merge(df1,df2,on=['alpha','beta'],how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （6）基于index的连接方法\n",
    "* 前面介绍了基于column的连接方法，merge方法亦可基于index连接dataframe。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于column和index的右连接\n",
    "# 定义df1\n",
    "df1 = pd.DataFrame({'alpha':['A','B','B','C','D','E'],'beta':['a','a','b','c','c','e'],\n",
    "                    'feature1':[1,1,2,3,3,1],'feature2':['low','medium','medium','high','low','high']})\n",
    "# 定义df2\n",
    "df2 = pd.DataFrame({'alpha':['A','A','B','F'],'pazham':['apple','orange','pine','pear'],\n",
    "                        'kilo':['high','low','high','medium'],'price':np.array([5,6,5,7])},index=['d','d','b','f'])\n",
    "print(df1)\n",
    "print(df2)\n",
    "\n",
    "# 基于df1的beta列和df2的index连接\n",
    "pd.merge(df1,df2,how='inner',left_on='beta',right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.3.6.2 join方法\n",
    "* join方法是基于index连接dataframe，merge方法是基于column连接，连接方法有内连接，外连接，左连接和右连接，与merge一致。 \n",
    "\n",
    "#### （1）index与index的连接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caller = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'], 'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
    "other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],'B': ['B0', 'B1', 'B2']})\n",
    "print(caller)\n",
    "print(other)  #lsuffix和rsuffix设置连接的后缀名\n",
    "caller.join(other,lsuffix='_caller', rsuffix='_other',how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）join也可以基于列进行连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caller = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'], 'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
    "other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],'B': ['B0', 'B1', 'B2']})\n",
    "print(caller)\n",
    "print(other)\n",
    "\n",
    "# 基于key列进行连接\n",
    "caller.set_index('key').join(other.set_index('key'),how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，join和merge的连接方法类似，这里就不展开join方法了，建议用merge方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.3.6.3 concat函数\n",
    "* concat函数是拼接函数，有行拼接和列拼接，默认是行拼接，拼接方法默认是外拼接（并集），拼接的对象是pandas数据类型。 \n",
    "\n",
    "#### （1）series类型的拼接方法\n",
    "\n",
    "#### 行拼接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.Series([1.1,2.2,3.3],index=['i1','i2','i3'])\n",
    "df2 = pd.Series([4.4,5.5,6.6],index=['i2','i3','i4'])\n",
    "print(df1)\n",
    "print(df2)\n",
    "\n",
    "# 行拼接\n",
    "pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 列拼接：\n",
    "* 默认以并集的方式拼接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列拼接,默认是并集\n",
    "pd.concat([df1,df2],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 以交集的方式拼接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列拼接的内连接（交）\n",
    "pd.concat([df1,df2],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 设置列拼接的列名："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列拼接的内连接（交）\n",
    "pd.concat([df1,df2],axis=1,join='inner',keys=['fea1','fea2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对指定的索引拼接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定索引[i1,i2,i3]的列拼接\n",
    "pd.concat([df1,df2],axis=1,join_axes=[['i1','i2','i3']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）dataframe类型的拼接方法\n",
    "\n",
    "#### 行拼接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'], 'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
    "df2 = pd.DataFrame({'key': ['K0', 'K1', 'K2'],'B': ['B0', 'B1', 'B2']})\n",
    "print(df1)\n",
    "print(df2)\n",
    "\n",
    "# 行拼接\n",
    "pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 列拼接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **注意：若列拼接或行拼接有重复的列名和行名，则报错。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断是否有重复的列名，若有则报错\n",
    "pd.concat([df1,df2],axis=1,verify_integrity = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.7 分类数据（属性数据）\n",
    "* pandas中可以把DataFrame实例对象的数据转化为**categorical类型**的数据；\n",
    "    * 以实现类似于一般统计分析软件中的值标签(value label)功能，便于分析结果的展示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students=pd.DataFrame({\"Name\":['Morgan','Jackie','Tom','John','Lucy','Mike','Rose'],\n",
    "                      \"Gender\":[1,0,0,1,0,1,2],\n",
    "                      \"Blood\":['A','AB','O','AB','B','O','A'],\n",
    "                      \"Grade\":[1,2,3,2,3,1,2],\n",
    "                      \"Height\":[175,180,168,170,158,183,173]})\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 将上述students对象中的Gender列挂上性别标签：\n",
    "    * Step 1：DataFrame的**astype方法**可将原始数据转化为category类型；\n",
    "    * Step 2：利用**cat.categories**为数据挂上标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students[\"GenderValue\"]=students[\"Gender\"].astype(\"category\")\n",
    "print(students)\n",
    "students[\"GenderValue\"].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students[\"GenderValue\"].cat.categories=['Female','Male','Unconfirmed']\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如需剔除或增加值标签，或者将类别设置为预定的尺度，可以使用**cat.set_categories方法**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students[\"GenderValue\"].cat.set_categories=['Male','Female','Unconfirmed']\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.groupby(\"GenderValue\").describe()  #分组描述统计分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.groupby(\"Gender\").describe()  #分组描述统计分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.4 时间序列\n",
    "* 时间序列在pandas中只不过是**索引比较特殊的Series或DataFrame**；\n",
    "    * 其最主要也是最基本的特点就是**以时间戳(TimeStamp)为索引**。\n",
    "    * TimeStamp与Python基本库中的Datetime（第3.2.8小节）是等价的。\n",
    "\n",
    "#### 表：三种数据分类对比\n",
    "|数据类型|描述|目的|示例|分析方法 |\n",
    "|--|--|--|--|--|\n",
    "|横截面数据(Cross-sectional data)|某一时点不同对象的数据|研究某一时点上的某种经济现象，突出空间(对象)的差异|北京，上海，深圳，广州某一天的平均温度||\n",
    "|时间序列数据(Time-series data)|同一对象在不同时间连续观察的数据|研究对象在时间顺序上的变化，寻找空间(对象)历时发展的规律|北京一年来每天的平均温度。 |主要围绕时间变化，可看总体趋势、季节性、周期性、ARIMA（自回归，滑动平均，差分）等|\n",
    "|纵向数据(Longitudinal data)或面板数据(Panel data)|截面数据与时间序列综合起来的一种数据资源|分析各样本在时间序列上组成的数据的特征，它能够综合利用样本信息，既可以分析个体之间的差异情况，又可以描述个体的动态变化特征|北京，上海，深圳，广州这一年来每天的平均温度|主要围绕统计个体区别，可用线性回归、主成分分析等|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.5 面板数据（Python3不适用）\n",
    "* pandas的名称就来自于面板数据(panel data)和数据分析(data analysis)。\n",
    "* **面板数据**：指在时间序列上取多个截面，在这些截面上同时选取样本观察值所构成的样本数据。\n",
    "    * 类似三维DataFrame，可用**堆积DataFrame**来实现，即：**Panel相当于一个存储DataFrame的字典**；\n",
    "    * 面板数据是计量经济学中时间序列数据的一种重要类型；\n",
    "    * 在生物统计领域也被称为**纵向数据**(longitudinal data)。\n",
    "    \n",
    "#### 表：面板数据示例\n",
    "|月份|姓名|收入(元)|请假次数|\n",
    "|--|--|--|--|\n",
    "|1月|张三|18000|2|\n",
    "||李四|21000|1|\n",
    "|2月|张三|20000|1|\n",
    "||李四|23000|0|\n",
    "|3月|张三|26000|0|\n",
    "||李四|32000|1|\n",
    "\n",
    "即：\n",
    "\n",
    "|姓名|月份|收入(元)|请假次数|\n",
    "|--|--|--|--|\n",
    "|张三|1月|18000|2|\n",
    "||2月|20000|1|\n",
    "||3月|26000|0|\n",
    "\n",
    "|姓名|月份|收入(元)|请假次数|\n",
    "|--|--|--|--|\n",
    "|李四|1月|21000|1|\n",
    "||2月|23000|0|\n",
    "||3月|32000|1|\n",
    "\n",
    "#### 例：用堆积DataFrame创建上表中的面板数据，即将“三维DataFrame”转化为二维DataFrame。\n",
    "|姓名|月份|收入(元)|请假次数|\n",
    "|--|--|--|--|\n",
    "|张三|1月|18000|2|\n",
    "|张三|2月|20000|1|\n",
    "|张三|3月|26000|0|\n",
    "|李四|1月|21000|1|\n",
    "|李四|2月|23000|0|\n",
    "|李四|3月|32000|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.6 缺失值处理\n",
    "* pandas中使用**np.nan**来表示缺失值。\n",
    "* 在默认的数据运算及分析过程中，缺失值不会参与分析过程。\n",
    "\n",
    "### 14.6.1 缺失数据的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students=pd.DataFrame({\"Name\":['Morgan','Jackie','Tom','John'],\n",
    "                      \"Gender\":['Male','Female','Female','Male'],\n",
    "                      \"Blood\":['A','AB','O','B'],\n",
    "                      \"Height\":[175,180,168,170]})\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "students[\"Python\"]=[80,np.nan,None,90]\n",
    "students[\"Math\"]=['A',np.nan,None,'C']\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **总结**：pandas对象中的缺失值有两种形式：\n",
    "    * NaN：数值型数据的np.nan和None以及字符型数据的np.nan\n",
    "    * None：字符型数据的None\n",
    "* **判断数据中是否含有缺失值：**\n",
    "    * isnull方法\n",
    "    * notnull方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.6.2 缺失数据填充与清洗\n",
    "\n",
    "#### （1）填充：fillna方法\n",
    "|参数|说明|备注|\n",
    "|--|--|--|\n",
    "|value|填充缺失值的标量或字典对象||\n",
    "|**method**|指定填充方式'backfill'或'bfill'（后向填充）,'pad'或'ffill'（前向填充），None|**默认为None**|\n",
    "|axis|指定待填充的轴0,1(或'index','columns')|默认为axis=0，即'index'|\n",
    "|inplace|指定是否修改对象上的任何其他视图|默认为否|\n",
    "|limit|指定'ffill'和'backfill'可连续填充的最大数量||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.fillna(0)  #value和method参数不能同时赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.fillna(method='bfill')  #后向填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.fillna(method='ffill')  #前向填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.fillna('missing',limit=1)  #有连续缺失值，只填充第一行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）填充：ffill方法、bfill方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(students.ffill())  #前向填充\n",
    "students.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(students.bfill())  #后向填充\n",
    "students.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）清洗：dropna方法\n",
    "* **清洗**：直接对含有缺失值的数据进行删除。\n",
    "    * 适用情形：数据量较大且缺失数据较少\n",
    "\n",
    "|参数|说明|备注|\n",
    "|--|--|--|\n",
    "|how='any'|删除含有任意缺失值的行或列|默认值|\n",
    "|how='all'|删除全部数据均为缺失值的行或列||\n",
    "|axis=0|删除行|默认值|\n",
    "|axis=1|删除列||\n",
    "|thresh|删除非缺失数据数量小于参数值的行或列||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （4）插值：interpolate方法\n",
    "* 具体插值方法需要通过**method参数**进行设置；\n",
    "* 参数值有：linear（默认）、time、index、spline等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|参数|描述|参数值|说明|备注|\n",
    "|--|--|--|--|--|\n",
    "|method|设定使用的插值技术|**默认为'linear'**|忽略索引，并将值等距地对待|这是MultiIndexes支持的唯一方法|\n",
    "|||‘time’|处理每日和更高分辨率的数据以内插给定的时间间隔长度||\n",
    "|||‘index’，‘values’：使用索引的实际数值||\n",
    "|||‘pad’：使用现有值填写NaN||\n",
    "|||‘nearest’，‘zero’，‘slinear’，‘quadratic’，‘cubic’，‘spline’，‘barycentric’，‘polynomial’|这些方法使用索引的数值|‘polynomial’和‘spline’要求指定一个order(int)|\n",
    "|axis|沿轴进行插补|**默认为 None**|||\n",
    "|||0或‘index’|||\n",
    "|||1或‘columns’|||\n",
    "|limit|设定要填充的连续NaN的最大数量|int||必须大于0|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
